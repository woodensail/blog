---
title: 数据分析S103：使用结巴分词工具提取关键词
tags:
  - python
  - 数据分析
id: 99
categories:
  - python
date: 2015-03-31 13:10:17
---

这一主要是使用[](https://github.com/fxsjy/jieba "结巴分词")进行分词，并提取关键词。

##### 根据词频分析：

这是利用结巴分词后，除去黑名单，统计得到出现最多的次，方法简单。但是没有利用到结巴提供的工具，因此效果较差
[python]
def pet_phrase(usrid=None, name=None):
    with open(r'resource/stopWordList.txt',encoding='utf-8') as f:
        black_list=[i for i in f.read().split('\n')]
    speak_list=dataio.someonechat(usrid,name)
    rate={}
    for sentence in speak_list:
        for word in posseg.cut(sentence['contents']):
            s=word.word
            if rate.get(s):
                rate[s]+=1
            elif s not in black_list:
                rate[s]=1
    return sorted(rate.items(),key=lambda x:x[1],reverse=True)[:10]
[/python]
&nbsp;

##### 利用结巴分析模块：

[python]
result = '\n'.join([i[0] for i in conn.execute('SELECT contents FROM chatdb')])
print(jieba.analyse.extract_tags(result, 10))
print(jieba.analyse.textrank(result,10))
[/python]